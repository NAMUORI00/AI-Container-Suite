{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch CUDA 테스트 노트북\n",
    "이 노트북은 PyTorch와 CUDA가 제대로 설정되었는지 확인하기 위한 기본 테스트를 포함하고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PyTorch 및 CUDA 버전 확인\n",
    "PyTorch와 CUDA 버전이 올바르게 설정되었는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 날짜 및 시간: 2025-04-08 04:40:23\n",
      "운영체제: Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.35\n",
      "Python 버전: 3.10.16\n",
      "PyTorch 버전: 2.2.2\n",
      "CUDA 사용 가능: True\n",
      "CUDA 버전: 12.1\n",
      "cuDNN 버전: 8902\n",
      "사용 가능한 GPU 개수: 1\n",
      "GPU 0: NVIDIA GeForce RTX 4060 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import platform\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"현재 날짜 및 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"운영체제: {platform.platform()}\")\n",
    "print(f\"Python 버전: {platform.python_version()}\")\n",
    "print(f\"PyTorch 버전: {torch.__version__}\")\n",
    "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA 버전: {torch.version.cuda}\")\n",
    "print(f\"cuDNN 버전: {torch.backends.cudnn.version() if torch.backends.cudnn.is_available() else '사용 불가'}\")\n",
    "print(f\"사용 가능한 GPU 개수: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 기본 CUDA 텐서 작업\n",
    "CUDA를 사용하여 기본 텐서 작업을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU 텐서:\n",
      "tensor([[0.8993, 0.5611, 0.3627],\n",
      "        [0.6949, 0.8376, 0.3835],\n",
      "        [0.8757, 0.5431, 0.1674],\n",
      "        [0.6420, 0.8558, 0.2687],\n",
      "        [0.0568, 0.8261, 0.3783]])\n",
      "\n",
      "GPU에서 생성된 텐서:\n",
      "tensor([[0.9727, 0.0053, 0.9023],\n",
      "        [0.0391, 0.3300, 0.3857],\n",
      "        [0.2901, 0.1819, 0.5613],\n",
      "        [0.9572, 0.0142, 0.1316],\n",
      "        [0.6711, 0.4393, 0.3736]], device='cuda:0')\n",
      "\n",
      "CPU에서 GPU로 이동된 텐서:\n",
      "tensor([[0.8993, 0.5611, 0.3627],\n",
      "        [0.6949, 0.8376, 0.3835],\n",
      "        [0.8757, 0.5431, 0.1674],\n",
      "        [0.6420, 0.8558, 0.2687],\n",
      "        [0.0568, 0.8261, 0.3783]], device='cuda:0')\n",
      "\n",
      "x 텐서 장치: cpu\n",
      "x_gpu 텐서 장치: cuda:0\n",
      "x_to_gpu 텐서 장치: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# CPU와 GPU 텐서 생성 및 이동\n",
    "x = torch.rand(5, 3)\n",
    "print(f\"CPU 텐서:\\n{x}\\n\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # GPU에서 텐서 생성\n",
    "    x_gpu = torch.rand(5, 3, device='cuda')\n",
    "    print(f\"GPU에서 생성된 텐서:\\n{x_gpu}\\n\")\n",
    "    \n",
    "    # CPU 텐서를 GPU로 이동\n",
    "    x_to_gpu = x.to('cuda')\n",
    "    print(f\"CPU에서 GPU로 이동된 텐서:\\n{x_to_gpu}\\n\")\n",
    "    \n",
    "    # 텐서가 위치한 장치 확인\n",
    "    print(f\"x 텐서 장치: {x.device}\")\n",
    "    print(f\"x_gpu 텐서 장치: {x_gpu.device}\")\n",
    "    print(f\"x_to_gpu 텐서 장치: {x_to_gpu.device}\")\n",
    "else:\n",
    "    print(\"CUDA가 사용 불가능합니다. CPU에서만 텐서 작업을 수행합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 간단한 벤치마킹 - CPU vs GPU\n",
    "CPU와 GPU에서 행렬 곱셈 연산 속도를 비교합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU vs GPU 행렬 곱셈 벤치마크 (10회 반복 평균 시간)\n",
      "--------------------------------------------------\n",
      "        크기 |         CPU (초) |         GPU (초) |           속도 향상\n",
      "--------------------------------------------------\n",
      "       128 |        0.001274 |        0.001630 |            0.78x\n",
      "       512 |        0.005250 |        0.003285 |            1.60x\n",
      "      1024 |        0.037085 |        0.024539 |            1.51x\n",
      "      2048 |        0.238752 |        0.183460 |            1.30x\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# 벤치마크 함수 정의\n",
    "def benchmark_matmul(size, device='cpu'):\n",
    "    \"\"\"\n",
    "    행렬 곱셈 연산 벤치마킹\n",
    "    \"\"\"\n",
    "    a = torch.randn(size, size, device=device)\n",
    "    b = torch.randn(size, size, device=device)\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        torch.cuda.synchronize()  # 정확한 타이밍을 위해 CUDA 작업이 완료될 때까지 대기\n",
    "        \n",
    "    start = time.time()\n",
    "    \n",
    "    # 행렬 곱셈 수행\n",
    "    for _ in range(10):\n",
    "        c = torch.matmul(a, b)\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    end = time.time()\n",
    "    return end - start\n",
    "\n",
    "# 다양한 크기로 벤치마크 실행\n",
    "sizes = [128, 512, 1024, 2048]\n",
    "\n",
    "print(\"CPU vs GPU 행렬 곱셈 벤치마크 (10회 반복 평균 시간)\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'크기':>10} | {'CPU (초)':>15} | {'GPU (초)':>15} | {'속도 향상':>15}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for size in sizes:\n",
    "    cpu_time = benchmark_matmul(size, 'cpu')\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        gpu_time = benchmark_matmul(size, 'cuda')\n",
    "        speedup = cpu_time / gpu_time\n",
    "    else:\n",
    "        gpu_time = float('nan')\n",
    "        speedup = float('nan')\n",
    "    \n",
    "    print(f\"{size:10d} | {cpu_time:15.6f} | {gpu_time:15.6f} | {speedup:15.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. TensorRT 가용성 확인\n",
    "TensorRT가 설치되어 있는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorRT 임포트 오류: No module named 'tensorrt'\n",
      "해결 방법: pip install tensorrt 또는 apt install nvidia-tensorrt 실행\n",
      "torch-tensorrt 임포트 오류: No module named 'torch_tensorrt'\n",
      "torch-tensorrt는 선택적으로 사용 가능합니다: pip install torch-tensorrt\n"
     ]
    }
   ],
   "source": [
    "# TensorRT 설치 확인\n",
    "try:\n",
    "    import tensorrt as trt\n",
    "    print(f\"TensorRT 버전: {trt.__version__}\")\n",
    "    print(\"TensorRT가 성공적으로 설치되었습니다.\")\n",
    "except ImportError:\n",
    "    print(\"TensorRT가 설치되지 않았거나 Python 환경에서 접근할 수 없습니다.\")\n",
    "\n",
    "# torch-tensorrt 확인 시도(선택 사항)\n",
    "try:\n",
    "    import torch_tensorrt\n",
    "    print(f\"torch-tensorrt 버전: {torch_tensorrt.__version__}\")\n",
    "    print(\"torch-tensorrt가 설치되었습니다.\")\n",
    "except ImportError:\n",
    "    print(\"torch-tensorrt가 설치되어 있지 않습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 간단한 CNN 모델 훈련 예제\n",
    "GPU를 활용한 간단한 CNN 모델 훈련 예제입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 패키지 설치 확인 (필요한 경우 주석 해제)\n",
    "!pip install transformers datasets evaluate accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_metric' from 'datasets' (/opt/conda/envs/pytorch_env/lib/python3.10/site-packages/datasets/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_metric\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 장치 선택\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_metric' from 'datasets' (/opt/conda/envs/pytorch_env/lib/python3.10/site-packages/datasets/__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "import random\n",
    "\n",
    "# 장치 선택\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"훈련에 사용할 장치: {device}\")\n",
    "\n",
    "# 재현성을 위한 시드 설정\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "try:\n",
    "    # 작은 텍스트 분류 데이터셋 로드 (SST-2)\n",
    "    dataset = load_dataset(\"glue\", \"sst2\", split=[\"train[:1000]\", \"validation[:200]\"])\n",
    "    train_dataset, eval_dataset = dataset[0], dataset[1]\n",
    "    print(f\"훈련 데이터셋 크기: {len(train_dataset)}\")\n",
    "    print(f\"평가 데이터셋 크기: {len(eval_dataset)}\")\n",
    "    \n",
    "    # 토크나이저 및 모델 로드\n",
    "    model_name = \"distilbert-base-uncased\"  # 작은 모델 사용\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2).to(device)\n",
    "    \n",
    "    # 데이터셋 전처리\n",
    "    def preprocess_function(examples):\n",
    "        return tokenizer(examples[\"sentence\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "    \n",
    "    encoded_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "    encoded_eval_dataset = eval_dataset.map(preprocess_function, batched=True)\n",
    "    \n",
    "    # 평가 메트릭 정의\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        return {\"accuracy\": np.mean(predictions == labels)}\n",
    "    \n",
    "    # 훈련 인자 설정 \n",
    "    batch_size = 16\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        num_train_epochs=1,  # 테스트를 위한 1 에포크\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        warmup_steps=50,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_steps=10,\n",
    "        eval_steps=50,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_steps=1000,  # 저장 비활성화\n",
    "        save_strategy=\"steps\",\n",
    "        load_best_model_at_end=False,  # 테스트를 위해 비활성화\n",
    "        report_to=\"none\",  # 리포팅 비활성화\n",
    "    )\n",
    "    \n",
    "    # 트레이너 초기화\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=encoded_train_dataset,\n",
    "        eval_dataset=encoded_eval_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    \n",
    "    # 시간 측정 시작\n",
    "    print(\"\\n학습 시작...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 학습 실행 (예시 삼아 3 스텝만)\n",
    "    max_steps = 3\n",
    "    train_results = trainer.train(max_steps=max_steps)\n",
    "    \n",
    "    # 시간 측정 종료\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    # 평가 실행\n",
    "    eval_results = trainer.evaluate()\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f\"\\n{max_steps} 스텝 훈련 완료!\")\n",
    "    print(f\"훈련 시간: {training_time:.2f}초 (스텝당 {training_time/max_steps:.2f}초)\")\n",
    "    print(f\"평가 정확도: {eval_results['eval_accuracy']:.4f}\")\n",
    "    print(f\"평가 손실: {eval_results['eval_loss']:.4f}\")\n",
    "    print(f\"사용한 장치: {device}\")\n",
    "    \n",
    "    # 모델 메모리 사용량 출력\n",
    "    if torch.cuda.is_available():\n",
    "        memory_allocated = torch.cuda.memory_allocated(0) / 1024**2\n",
    "        memory_reserved = torch.cuda.memory_reserved(0) / 1024**2\n",
    "        print(f\"CUDA 메모리 할당: {memory_allocated:.2f} MB\")\n",
    "        print(f\"CUDA 메모리 예약: {memory_reserved:.2f} MB\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"훈련 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hugging Face Diffusion 모델을 활용한 이미지 생성 테스트\n",
    "Hugging Face의 Diffusion 모델을 사용하여 GPU 성능을 테스트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 패키지 설치 확인 (필요한 경우 주석 해제)\n",
    "# !pip install diffusers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 생성에 사용할 장치: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't connect to the Hub: 404 Client Error. (Request ID: Root=1-67f4a924-7bb53f7936e8a29a37120af0;9ff733fa-a744-4740-ad46-b15c6f102ac6)\n",
      "\n",
      "Revision Not Found for url: https://huggingface.co/api/models/stable-diffusion-v1-5/stable-diffusion-v1-5/revision/fp16.\n",
      "Invalid rev id: fp16.\n",
      "Will try to load from local cache.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 생성 중 오류 발생: Cannot load model runwayml/stable-diffusion-v1-5: model is not cached locally and an error occurred while trying to fetch metadata from the Hub. Please check out the root cause in the stacktrace above.\n",
      "메모리 부족 오류가 발생한 경우 다음을 시도해 보세요:\n",
      "1. 더 작은 해상도 설정 (height=384, width=384)\n",
      "2. 더 적은 inference_steps 설정 (예: 15)\n",
      "3. 더 적은 VRAM을 사용하는 모델 선택 (예: CompVis/stable-diffusion-v1-4)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from IPython.display import display\n",
    "\n",
    "# 장치 확인\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"이미지 생성에 사용할 장치: {device}\")\n",
    "\n",
    "try:\n",
    "    if torch.cuda.is_available():\n",
    "        # GPU 메모리 사용량을 줄이기 위한 설정\n",
    "        model_id = \"runwayml/stable-diffusion-v1-5\"  # 가장 널리 사용되는 모델\n",
    "        \n",
    "        # 메모리 최적화 옵션과 함께 모델 로드\n",
    "        torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "        pipe = StableDiffusionPipeline.from_pretrained(\n",
    "            model_id, \n",
    "            torch_dtype=torch_dtype,\n",
    "            revision=\"fp16\",\n",
    "            use_safetensors=True\n",
    "        )\n",
    "        pipe = pipe.to(device)\n",
    "        \n",
    "        # 추가 메모리 최적화\n",
    "        pipe.enable_attention_slicing()\n",
    "        \n",
    "        # 프롬프트 설정 및 이미지 생성\n",
    "        prompt = \"한국의 아름다운 야경 사진, 서울 남산타워\"\n",
    "        \n",
    "        # 이미지 생성 시간 측정\n",
    "        print(\"\\n이미지 생성 시작...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # 이미지 생성\n",
    "        with torch.autocast(\"cuda\"):\n",
    "            image = pipe(prompt, num_inference_steps=20, height=512, width=512).images[0]\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        # 결과 표시\n",
    "        print(f\"이미지 생성 완료! 소요 시간: {end_time - start_time:.2f}초\")\n",
    "        display(image)\n",
    "        \n",
    "        # 메모리 사용량 출력\n",
    "        memory_allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "        memory_reserved = torch.cuda.memory_reserved(0) / 1024**3\n",
    "        print(f\"CUDA 메모리 할당: {memory_allocated:.2f} GB\")\n",
    "        print(f\"CUDA 메모리 예약: {memory_reserved:.2f} GB\")\n",
    "    else:\n",
    "        print(\"CUDA를 사용할 수 없어 이미지 생성 테스트를 건너뜁니다.\")\n",
    "        print(\"이 테스트는 최소 10GB 이상의 VRAM이 필요합니다.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"이미지 생성 중 오류 발생: {e}\")\n",
    "    print(\"메모리 부족 오류가 발생한 경우 다음을 시도해 보세요:\")\n",
    "    print(\"1. 더 작은 해상도 설정 (height=384, width=384)\")\n",
    "    print(\"2. 더 적은 inference_steps 설정 (예: 15)\")\n",
    "    print(\"3. 더 적은 VRAM을 사용하는 모델 선택 (예: CompVis/stable-diffusion-v1-4)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
